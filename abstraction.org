* Motivation
This is an attempt to better understand how the process of abstraction can be used in computational models of intelligence.  It is also an experiment in literate-style programming and questions related to literate programming will be prefaced with LP?
* Approach
One way to formulate the problem of modeling intelligence is by vieweing it as a process of inference over incomplete data influenced by previously perceived data.  As a starting point we can imagine data as being a (possibly nested) list of symbols.  An inference problem can be described as a (possibly nested) list containing variables where the variables represent an unknown part of the list that should be filled in.
* Examples
** Binary Classification
An example of a problem that can be formulated in terms of inference on lists is classification of binary data.  We can write input data as
#+name: binary_data
#+begin_src python :results value
pattern0 = [[[1], 0], [[1,1], 0], [[1,1,1,1,1], 0], [[1,1], 0]]
pattern1 = [[[1,1,0,0],1], [[1,1,1,0,0,0],1], [[1,1,1,1,0,0,0,0],1]]
#+end_src

With org-mode's literate programming support we can display this data in a nice format like so
#+begin_src python :results value :noweb yes
  <<binary_data>>
  return pattern0+pattern1
#+end_src

#+RESULTS:
| (1)               | 0 |
| (1 1)             | 0 |
| (1 1 1 1 1)       | 0 |
| (1 1)             | 0 |
| (1 1 0 0)         | 1 |
| (1 1 1 0 0 0)     | 1 |
| (1 1 1 1 0 0 0 0) | 1 |

*** First Approximation
A simple (but expected to be poor performing) algorithm for the inference problem would be to store every piece of data then when an inference problem (i.e. partial piece of data) is faced we try to match what is known to any of the pieces of data that have already been seen and then use a matching piece of data to fill in the unknowns in the inference problem.  

Even though it's not hard to think of cases where this algorithm won't work, we start with this problem to build up some of the general infrastructure for modeling inference and abstraction and make the idea of modeling intelligence as inference on lists more concrete.

**** TODO Storing data
The first part of the algorithm is to store data.  We'll use a list as the data structure to keep things simple for now, but use a layer of abstraction to manipulate it.
#+name: memory
#+begin_src python :tangle yes
  class Memory:
      memory = []
      def add(self, data):
          self.memory.append(data)
  
#+end_src
Now we test the function using the binary data from earlier
#+name: add_pattern0_to_memory
#+begin_src python :noweb yes
  <<binary_data>>
  <<memory>>
  memory = Memory()
  for data in pattern0:
      memory.add(data)
  

  
#+end_src

#+name: return_memory
#+begin_src python :noweb yes
  <<add_pattern0_to_memory>>
  
  return memory.memory
#+end_src

#+RESULTS: return_memory
| (1)         | 0 |
| (1 1)       | 0 |
| (1 1 1 1 1) | 0 |
| (1 1)       | 0 |


***** LP? Python mode in src blocks?
What is the best way to edit code in the source blocks?  By default, emacs seems to be in org-mode.
****** C-c '
http://orgmode.org/manual/Editing-source-code.html#Editing-source-code

**** Inference
Now that we have a way to hold prior data we want to be able to use that data to solve inference problems.  Let's formalize our earlier approach of inference on nested lists.
***** Inference Formulation
An inference problem can be described as a list with some variables that represent unknown parts of the list.  Elements of the list can be either lists, symbols, or variables.  In code the class might look like

#+name: inference_problem
#+begin_src python :tangle yes
  class InferenceProblem:
      #variables that might appear in partial_data
      variables = []
      partial_data = []
  
      def __init__(self, initial_variables, initial_partial_data):
          self.variables = initial_variables
          self.partial_data = initial_partial_data
  
#+end_src

We could make the typing more explicit by performing checks during instantiation of the class, but we'll leave it unless this becomes an issue.

It's also worth noting that an inference problem is essentially the same thing as an abstraction.  Perhaps we'll use some kind of type aliasing if it becomes helpful when we explore abstraction-based approaches to inference.

****** Binary Data Inference Problems
******* Classification
One example of an inference problem is classification of binary data.  Suppose we have some data from either pattern0 or pattern1 above as shown earlier and we want to infer the pattern it came from, we can create a problem like so
#+name: binary_data_classification_problems
#+begin_src python :results output :noweb yes :tangle no

  classify_problem0 = InferenceProblem(['v0'],[[1,1,1,1], 'v0'])  
  classify_problem1 = InferenceProblem(['v0'], [[1,1,1,0,0,0], 'v0'])

#+end_src


The solution for classify_problem0 being v0 is [0] and the solution for classify_problem1 being v0 is [1].  The reason the solutions are in a list is that variables may represent several missing elements in a list.  This is better illustrated in the next example.
******* Completion
Another type of problem would be to infer parts of the binary data given we know the pattern e.g.

#+name: binary_data_completion_problems
#+begin_src python :results output :noweb yes :tangle 
  complete_problem0 = InferenceProblem(['v0'], [[1,1,1,'v0'], 1])
  complete_problem1 = InferenceProblem(['v0', 'v1'], [['v0', 1, 'v1'], 0])
#+end_src
The solution for the first problem intuitively is v0 is [0, 0, 0].  The second problem, complete_problem1, raises the issue that problems do not necessarily have a unique answer.  For this problem v1 and v2 could be lists of 1 of arbitrary length e.g. v0 is [1, 1, 1] and v1 is [1] or v0 is [1,1] and v1 is [1,1,1,1].  We'll take a closer look at solutions to inference problems and evaluating them in the next section.

****** Binary Data Solutions
An inference problem is a set of variables along with a list containing those variables.  The solution to inference problems are values that are assigned to those variables (bindings or an environment) and are substituted in the following way.

#+name: substitute_function
#+begin_src python :results value :tangle yes
  def substitute(partial_data, bindings):
      """
      replace variables in the abstraction with the matching values in the bindings
      and return the resulting list
      """
      complete_list = []
      for element in partial_data:
          replacement = swap(element, bindings)
          complete_list += replacement
      return complete_list
  
  def swap(element, bindings):
          if element in bindings.keys():
              return bindings[element]
          elif isinstance(element, list):
              return [substitute(element, bindings)]
          else:
              return [element]
  
#+end_src

We can demonstrate the substitute function on our earlier examples of inference problems like so

#+name: substitution_examples
#+begin_src python :results output :noweb yes :tangle no
  <<substitute_function>>
  <<binary_data_classification_problems>>
  <<binary_data_completion_problems>>
  
  print substitute(classify_problem0.partial_data, {'v0': [0]})
  print substitute(classify_problem1.partial_data, {'v0': [1]})
  print substitute(complete_problem0.partial_data, {'v0': [0,0,0]})
  print substitute(complete_problem1.partial_data, {'v0': [1,1,1], 'v1': [1]})
  print substitute(complete_problem1.partial_data, {'v0': [1,1], 'v1': [1,1,1,1]})
#+end_src

#+RESULTS: substitution_examples
: ['v0']
: [[1, 1, 1, 1], 0]
: [[1, 1, 1, 0, 0, 0], 1]
: [[1, 1, 1, 0, 0, 0], 1]
: [[1, 1, 1, 1, 1], 0]
: [[1, 1, 1, 1, 1, 1, 1], 0]

#+RESULTS: subsitution_examples
Here we used the solutions, i.e. bindings, we thought were intuitively correct for each problem and we get completed lists that look like the prior data we had seen.

We assume for every inference problem there is some "true solution" or set of solutions for it and an algorithm for solving inference problems should try to produce the true solution for a given inference problem.

So for 
#+begin_src python
  classify_problem0 = InferenceProblem(['v0'],[[1,1,1,1], 'v0'])  
#+end_src 
the true solution could be defined as {'v0': [0]}.  
In the case of 
#+begin_src python
  complete_problem1 = InferenceProblem(['v0', 'v1'],[['v0',1,'v1'], 0])  
#+end_src 
the true solution might be the set of all lists containing 1s i.e. {[1], [1,1], [1,1,1],...}

How do we tell if one solution is better than the other?  So given
#+begin_src python
  complete_problem0 = InferenceProblem(['v0'],[[1,1,1,'v0'] '1'])  
  true_solution = {'v0', [0,0,0]}
#+end_src 
If we have an algorithm that has a choice between {'v0', [0,0,1]} and {'v0, [1,1,1]}, how does one compare the two solutions.  It's not clear, but this seems to be something that depends on the algorithm implementation rather than the problem specification.  In terms of the problem either the solution is incorrect or correct and in this case both solutions are incorrect since they don't match the true solution.

***** Algorithm for Inference
This section will describe more formally the simple algorithm for trying to solve inference problems introduced in the section "First Approximation."  Recall the idea is to create a solution, i.e. binding of variables, based on matching the partial data of the inference problem to previously seen data.  Another way to phrase it is we want to find an environment where the the partial data is the same as some prior data we've seen.

The process of matching seems like unification (http://en.wikipedia.org/wiki/Unification_(computer_science)) so it might be worth looking more into the literature if straight-forward approaches run into barriers.  For now though we'll develop our approach by looking at small examples and generalizing.  

Suppose our prior data consists of pattern0 i.e. we have executed the add_pattern0_to_memory code block and now we are faced with classify_problem0.  We want to try and match the partial data of classify_problem0 to the data we've already seen then use that to create a solution.
****** Matching
******* Implementation
Let's look at the pairing of partial data to previous data
#+name: iterate_match
#+begin_src python :results output :noweb yes :tangle no
  <<binary_data_classification_problems>>
  <<add_patter0_to_memory>>
  #TODO define an iterator for Memory to go through the saved data
  
  for memory in memory.memory:
      print classify_problem0.partial_data, memory
  
#+end_src

#+RESULTS: iterate_match
: [[1, 1, 1, 1], 'v0'] [[1], 0]
: [[1, 1, 1, 1], 'v0'] [[1, 1], 0]
: [[1, 1, 1, 1], 'v0'] [[1, 1, 1, 1, 1], 0]
: [[1, 1, 1, 1], 'v0'] [[1, 1], 0]

What should be the output of a matching e.g. if I try to match [[1, 1, 1, 1], 'v0'] with [[1], 0] what should the result be?  What about [[1, 1, 1, 1], 'v0'] and [[1, 1, 1, 1, 1], 0]?  In the future perhaps we'll develop a match function that returns {'v0': 0} as a binding for these two examples by making some sort of "best guess", but for a first pass let's assume there needs to be a perfect match of non-variable parts of the partial data for match to return any bindings (this may be enough when abstraction over prior data is added since matching against abstractions of prior data might have the same effect as making a best guess).  

We still must consider what to do when there are several possible valid matches.  An example being
#+name: example_data_many_matches
#+begin_src python  
  partial_data = [0, 'v0', 0, 'v1']
  prior_data = [0,1,0,1,0,1,0,1]
  
  valid_binding0 = {'v0': [1,0,1], 'v1': [1,0,1]}
  valid_binding1 = {'v0': [1], 'v1': [1,0,1,0,1]}
#+end_src

What is the return type for match? If there is no match then None should be returned.  Perhaps a single binding out of the possibly many bindings.  Maybe all the bindings.  In addition to the binding(s) it might also be useful to return some sort of score with the binding so that we may distinguish between the quality of different bindings.  What are the consequences of the different return types in the broader context of finding a solution to an inference problem?  

This raises another question worth asking about match is whether it should try to match to any part of the prior data or just the top level. E.g.
#name: example_sub_matching
#+begin_src python
  partial_data = [1,0,'v0']
  prior_data = [1,1,[1,0,1]]
  
  sub_match = {'v0', [1]}
#+end_src
Where the sub_match occurs from partial_data being matched to the third element of prior_data.  This is an interesting question because if this is the case then rather than viewing a solution to an inference problem as trying to match to each individual prior piece of data we can view the prior data as one large piece of data and solving the inference problem is a matter of finding a match of the partial_data to this single prior data object.  Either way we'll still probably want a function which matches only the top-level even if it's just a helper function.

In all cases it seems natural that the return of a matching should be a function of matching the individual elements of the partial data.  The possible types to be matched are primitives, variables, and lists.  

#+name: structure_for_match
#+begin_src python :noweb yes :tangle yes
  def match(partial_data, prior_data):
      if is_variable(partial_data):
          <<match_variable_case>>
      elif is_symbol(partial_data):
          if partial_data == prior_data:
              <<match_symbol_equal_case>>
          else:
              <<match_symbol_not_equal_case>>
      else:
          assert(isinstance(partial_data, list))
          if isinstance(prior_data, list) and len(prior_data) >= len(partial_data):
              #combine the results of matching the individual elements
              <<match_list_case>>
          else:
              <<match_list_no_match>>
#+end_src

The interesting case is when the partial_data is a list.  Let's use the data in example_data_many_matches to guide development of the algorithm.  For now we'll assume matching of the elements occurs via iteration over the list from left to right.  It's not clear why it would be beneficial to do so otherwise, but we'll tag this [DD] (design decision) and can revisit things aren't working.  

It's been asserted that the partial_data is a list, but before we start iterating through and matching elements there are a few checks on the prior_data we can do that would imply there is no match mainly if it is not a list or two small i.e. if there are not enough elements to match with partial_data.
  
Matching elements is kind of tricky because variables in the partial_data can match multiple elements of the corresponding prior_data so we need to keep track of the current position for both lists as we iterate through the partial_data.  

#+name: match_list_case
#+begin_src python :noweb yes 
  matches = []
  prior_data_position = 0
  for partial_data_position, partial_data_element in enumerate(partial_data):
      if is_variable(partial_data_element):
          #this case will need to increment prior_data_position appropriately
          #possibly several steps ahead of partial_data_position
          <<match_list_case_variable_case>>
      else:
          #if it's the last element of partial data and there is more than one element left in
          #prior data then it's not a match
          if partial_data_position == len(partial_data) - 1 and\
            len(prior_data[prior_data_position:]) > 1:
              return None
          else:
              matches.append(match(partial_data_element, prior_data[prior_data_position]))
              prior_data_position += 1
  <<match_list_case_combine_matches>>
  
#+end_src

At this point it's probably a good idea to look at the different possibilites for the return type of matching so we can fill in the missing pieces.
******** single binding no score
There are a couple ways to handle returning a single match.  For now if there is more than one choice we'll select one at random.

We were last looking at the list case of match, i.e.  matching elements of the partial_data to  elements of the  prior_data.  Here is an example of when the current/first element of the partial_data is a variable.
#+name: variable_case_matching_list_example
#+begin_src python :noweb yes
  partial_data = ['v0', 0, 'v1']
  prior_data = [1,0,1,0,1,0,0,1]
  #bindings for v0
  possible_binding0 = {'v0': [1], 'v1': [1,0,1,0,0,1]}
  possible_binding1 = {'v0': [1,0,1], 'v1': [0,1,0,0,1]}
  possible_binding2 = {'v0': [1,0,1,0,1], 'v1': [0,1]}
  possible_binding3 = {'v0': [1,0,1,0,1,0], 'v1':[1]}
#+end_src
The pattern seems to be v0 can match to any prefix of the prior_data ([1], [1,0,1], [1,0,1,0,1], [1,0,1,0,1,0]) that ends before the next character in the partial_data after the variable (0).

In the case where the current variable element is also the last element then it should be bound to the remaining prior_data.

#+name: match_list_case_variable_case
#+begin_src python :noweb yes 
  if partial_data_element == partial_data[-1]:
      matches.append({partial_data_element : prior_data[prior_data_position:]})
  else:
      next_element = partial_data[partial_data_position+1]
      try:
          <<match_list_case_variable_case_has_next_element>>
      except ValueError:
          return None
  
#+end_src

In the case where there is a next element after the current variable element then we can match the variable to any prefix in the prior_data where the element after the last element of the prefix matches the next element in the partial_data, just like in variable_case_matching_list_example for v0.  There is an additional constraint that the remaining prior data after the match must be of greater size than the remaining partial_data and we can ensure this holds by only looking for matches in prior_data up until the position for which the remaining prior_data is the same size as the remaining partial_data.

In the example variable_case_matching_list_example if element is 'v0' then next_element is 0 so we want to find all the positions in prior_data ([1,0,1,0,1,0,0,1]) of 0s e.g. 1, 3, 4, 5, such that there are enough remaining elements in prior_data to match the remaining partial_data. The amount of remaining partial_data is 1 (just the 'v1' element).  If we only look at positions in the prior_data before prior_data[-1:] then any match will have at least 1 element left in prior_data to match the remaining element in the partial_data.

#+name: match_list_case_variable_case_has_next_element
#+begin_src python :noweb yes 
  #iterate through the prefixes of prior_data and capture the possible results of matching the variable to it
  variable = partial_data_element
  #remember the possible variable bindings along with the corresponding prior_data_position
  possible_variable_bindings = []
  amount_remaining_needed = len(partial_data[partial_data_position+2:])
  #positions in the prior_data where the prior_data element matches the partial_data element that
  #comes after the variable that is being bound, look at all the positions in prior_data after the current and up to before the tail of prior where the tail is as long as the remaining partial_data
  matching_positions = [i for i in range(prior_data_position+1,len(prior_data[prior_data_position+1:-amount_remaining_needed])+1)
                        if prior_data[i] == next_element]
  
  if len(matching_positions) > 0:
      chosen_match_position = random.choice(matching_positions)
      #bind the prefix of prior_data that ends just before chosen_match_position
      variable_binding = {variable: prior_data[prior_data_position: chosen_match_position]}
      #skip ahead prior_data_position to the point of the match since that will be the next element in the iteration over partial_data
      prior_data_position = chosen_match_position
  
      matches.append(variable_binding)
  else:
      matches.append(None)
#+end_src

We'll need to include the random library when tangling, but what is the best way to do this?
#+name: libs
#+begin_src python :noweb yes :tangle yes
import random
#+end_src

The final part of the match case for lists is combining the matches for the elements in the list.  This means making sure none of the matches were invalid (i.e. had value None) and if everything is ok then merging all the bindings into a single dictionary to be returned.
#+name: match_list_case_combine_matches
#+begin_src python :noweb yes
  if None in matches:
      return None
  else:
      #TODO handle case of same variable appearing in multiple places in the list
      all_bindings = {}
      for bindings in matches:
          all_bindings = dict(all_bindings.items() + bindings.items())
      return all_bindings
#+end_src

The non-list cases for match are fairly straight-forward.
#+name: match_variable_case
#+begin_src python :noweb yes
  return {partial_data: prior_data}
#+end_src


#+name: match_symbol_equal_case
#+begin_src python :noweb yes
  return {}
#+end_src

#+name: match_symbol_not_equal_case
#+begin_src python :noweb yes
  return None
#+end_src

#+name: match_list_no_match
#+begin_src python :noweb yes
  return None 
#+end_src

We need to define a few helper functions in order to run match.  For the type check of whether something is a variable we'll assume for now that variables come in the form 'v' combined with a number e.g. 'v0', 'v142', 'v99'
#+name: is_variable
#+begin_src python :noweb yes :tangle yes
  def is_variable(thing):
      return isinstance(thing, str) and thing[0] == 'v' \
        and thing[1:].isdigit()
    
#+end_src


#+name: is_variable_test
#+begin_src python :results output :noweb yes
  <<is_variable>>
  
  print is_variable('v0')
  print is_variable('0')
  print is_variable('v302')
  
#+end_src

#+RESULTS: is_variable_test
: True
: False
: True

For symbols we'll assume a symbol is anything not a list.
#+name: is_symbol
#+begin_src python :noweb yes :tangle yes
  def is_symbol(thing):
      return not isinstance(thing, list)
#+end_src
******** multiple bindings no score
******** single binding with score
******** multiple bindings with score

  def match(partial_data, prior_data):
      
  Furthmore we can define types of lists as lists with variables in the top level, lists with variables in a deeper level, and lists without variables.  Now if we pair these possibilities 



TODO look at the case where pattern1 has been added to memory.
******** Returning a set of possible bindings
******* Testing
Now that we have an implementation let's try it on some of the examples from earlier starting with the binary data at the beginning of the document.  Recall we'll be trying to apply match to the partial data of an inference problem and the prior data we've stored in memory.  An example of data in memory could be the bit patterns in pattern0

#+begin_src python :noweb yes :results output 
  <<binary_data>>
  for pattern in pattern0:
      print pattern
#+end_src

#+RESULTS:
: [[1], 0]
: [[1, 1], 0]
: [[1, 1, 1, 1, 1], 0]
: [[1, 1], 0]

An example of prior data from an inference problem could be 
#+begin_src python :noweb yes :results output
  <<inference_problem>>
  <<binary_data_classification_problems>>
  print classify_problem0.partial_data
#+end_src

#+RESULTS:
: [[1, 1, 1, 1], 'v0']

Applying match to a case where it should match and shouldn't match would like the following

#+begin_src python :noweb yes :tangle no :results output
  print match([[1, 1, 1, 1], 'v0'], [[1, 1, 1, 1], 0])
  
  print match([[1, 1, 1, 1], 'v0'], [[1, 1, 1, 1, 1], 0])
#+end_src

#+RESULTS
: {'v0': [0]}
: None

We'll also want to look at the cases where matching can have several possibilities such as in variable_case_matching_list_example.

#+begin_src python :noweb yes :tangle no
  for i in range(10):
      print match(['v0', 0, 'v1'], [1,0,1,0,1,0,0,1]) 
#+end_src

#+RESULTS
: {'v0': [1, 0, 1], 'v1': [1, 0, 0, 1]}
: {'v0': [1, 0, 1, 0, 1], 'v1': [0, 1]}
: {'v0': [1, 0, 1, 0, 1], 'v1': [0, 1]}
: {'v0': [1, 0, 1, 0, 1], 'v1': [0, 1]}
: {'v0': [1, 0, 1], 'v1': [1, 0, 0, 1]}
: {'v0': [1, 0, 1, 0, 1, 0], 'v1': [1]}
: {'v0': [1, 0, 1, 0, 1, 0], 'v1': [1]}
: {'v0': [1, 0, 1, 0, 1], 'v1': [0, 1]}
: {'v0': [1], 'v1': [1, 0, 1, 0, 0, 1]}
: {'v0': [1, 0, 1], 'v1': [1, 0, 0, 1]}

Let's take these solutions and substitute them back into the partial data and verify they match the prior data.

#+begin_src python :noweb yes
for i in range(10):
    binding = match(['v0', 0, 'v1'], [1,0,1,0,1,0,0,1])
    print substitute(['v0', 0, 'v1'], binding)
#+end_src

#+RESULTS
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]

Now that we have one version of the match function (return single binding, no score), let's move on to complete the loop and return to other versions when the need arises.
****** Problem-solving loop
The original first/naive approach for solving inference problems was to iterate through the prior data and try to find any matches with the partial data.  We'll now formalize this process.  Let's define a class to organize the problem solving functions and data structures.  We'll call it an agent.  It has a memory and a function for taking in inference problems and returning a solution.

#+name: agent
#+begin_src python :noweb yes :tangle yes
  class Agent:
      def __init__(self):
          self.memory = Memory()
  
      def solve(self, inference_problem):
          <<agent_solve>>
#+end_src

In order to solve an inference problem, we'll first extract the partial_data then match it against everything in memory.  To keep things simple we'll return a random binding [DD] or None if no solution was found.

#+name: agent_solve
#+begin_src python :noweb yes
  solutions = [match(inference_problem.partial_data, prior_data)
               for prior_data in self.memory.memory]
  
  solutions = [solution for solution in solutions if solution != None]
  if solutions == []:
      return None
  else:
      return random.choice(solutions)
#+end_src

We can test the function on the original inference problem examples and binary data.

#+begin_src python :noweb yes :tangle yes
    <<binary_data>>
    <<binary_data_classification_problems>>
    <<binary_data_completion_problems>>
  
    agent = Agent()
    [agent.memory.add(data) for data in pattern0+pattern1]
    print 'In memory %s' % agent.memory.memory
  
    problems = [classify_problem0, classify_problem1, complete_problem0, complete_problem1]
    for problem in problems:
        print 'problem: %s' % problem.partial_data
        solution = agent.solve(problem)
        print 'solution: %s' % solution
        if solution is not None:
            print 'completion: %s' % substitute(problem.partial_data, solution)
  
#+end_src

#+RESULTS
: In memory [[[1], 0], [[1, 1], 0], [[1, 1, 1, 1, 1], 0], [[1, 1], 0], [[1, 1, 0, 0], 1], [[1, 1, 1, 0, 0, 0], 1], [[1, 1, 1, 1, 0, 0, 0, 0], 1]]
: 
: problem: [[1, 1, 1, 1], 'v0']
: solution: None
: problem: [[1, 1, 1, 0, 0, 0], 'v0']
: solution: {'v0': [1]}
: completion: [[1, 1, 1, 0, 0, 0], 1]
: problem: [[1, 1, 1, 'v0'], 1]
: solution: {'v0': [1, 0, 0, 0, 0]}
: completion: [[1, 1, 1, 1, 0, 0, 0, 0], 1]
: problem: [['v0', 1, 'v1'], 0]
: solution: {'v0': [1, 1, 1], 'v1': [1]}
: completion: [[1, 1, 1, 1, 1], 0]

***** Reflections
We won't go into depth testing this first approach on a wide variety of data since the main point was to work out some of the details for the setup of solving inference problems.  The major limitation of the algorithm was the inability to generalize.  An example was the problem [[1, 1, 1, 1], 'v0'] which intuitively has a solution of {'v0', [1]}.  One possible solution is to use abstraction, which we'll explore in the rest of the document. [add explanation on how abstraction can help]
*** Second Approximation
Our next attempt to solve inference problems will utilize the power of abstraction.  [give some intuitive examples of where abstraction is useful e.g. hierachical planning, etc].  The plan is

1) come up with a few additional inference problems staying with the same two patterns used in binary_data_classfiication_problems and binary_data_completion_problems; these will be used as references while developing the details of the algorithm
2) formally define a process of abstraction based on the lambda abstraction in lambda calculus
3) work out details of how abstraction happens when new data is added to memory as well as how data is stored
4) work out details for matching partial data to possibily abstract data in the memory
5) work out details of how matching is used in the larger problem solving routine
