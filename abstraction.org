* Motivation
This is an attempt to better understand how the process of abstraction can be used in computational models of intelligence.  It is also an experiment in literate-style programming and questions related to literate programming will be prefaced with LP?
* Approach
One way to formulate the problem of modeling intelligence is by vieweing it as a process of inference over incomplete data influenced by previously perceived data.  As a starting point we can imagine data as being a (possibly nested) list of symbols.  An inference problem can be described as a (possibly nested) list containing variables where the variables represent an unknown part of the list that should be filled in.
* Examples
** Binary Classification
An example of a problem that can be formulated in terms of inference on lists is classification of binary data.  We can write input data as
#+name: binary_data
#+begin_src python :results value
pattern0 = [[[1], 0], [[1,1], 0], [[1,1,1,1,1], 0], [[1,1], 0]]
pattern1 = [[[1,1,0,0],1], [[1,1,1,0,0,0],1], [[1,1,1,1,0,0,0,0],1]]
#+end_src

With org-mode's literate programming support we can display this data in a nice format like so
#+begin_src python :results value :noweb yes
  <<binary_data>>
  return pattern0+pattern1
#+end_src

#+RESULTS:
| (1)               | 0 |
| (1 1)             | 0 |
| (1 1 1 1 1)       | 0 |
| (1 1)             | 0 |
| (1 1 0 0)         | 1 |
| (1 1 1 0 0 0)     | 1 |
| (1 1 1 1 0 0 0 0) | 1 |

*** First Approximation
A simple (but expected to be poor performing) algorithm for the inference problem would be to store every piece of data then when an inference problem (i.e. partial piece of data) is faced we try to match what is known to any of the pieces of data that have already been seen and then use a matching piece of data to fill in the unknowns in the inference problem.  

Even though it's not hard to think of cases where this algorithm won't work, we start with this problem to build up some of the general infrastructure for modeling inference and abstraction and make the idea of modeling intelligence as inference on lists more concrete.

**** TODO Storing data
The first part of the algorithm is to store data.  We'll use a list as the data structure to keep things simple for now, but use a layer of abstraction to manipulate it.
#+name: memory
#+begin_src python :tangle yes
  class Memory:
      memory = []
      def add(self, data):
          self.memory.append(data)
  
#+end_src
Now we test the function using the binary data from earlier
#+name: add_pattern0_to_memory
#+begin_src python :noweb yes
  <<binary_data>>
  <<memory>>
  memory = Memory()
  for data in pattern0:
      memory.add(data)
  

  
#+end_src

#+name: return_memory
#+begin_src python :noweb yes
  <<add_pattern0_to_memory>>
  
  return memory.memory
#+end_src

#+RESULTS: return_memory
| (1)         | 0 |
| (1 1)       | 0 |
| (1 1 1 1 1) | 0 |
| (1 1)       | 0 |


***** LP? Python mode in src blocks?
What is the best way to edit code in the source blocks?  By default, emacs seems to be in org-mode.
****** C-c '
http://orgmode.org/manual/Editing-source-code.html#Editing-source-code

**** Inference
Now that we have a way to hold prior data we want to be able to use that data to solve inference problems.  Let's formalize our earlier approach of inference on nested lists.
***** Inference Formulation
An inference problem can be described as a list with some variables that represent unknown parts of the list.  Elements of the list can be either lists, symbols, or variables.  In code the class might look like

#+name: inference_problem
#+begin_src python :tangle yes
  class InferenceProblem:
      #variables that might appear in partial_data
      variables = []
      partial_data = []
  
      def __init__(self, initial_variables, initial_partial_data):
          self.variables = initial_variables
          self.partial_data = initial_partial_data
  
#+end_src

We could make the typing more explicit by performing checks during instantiation of the class, but we'll leave it unless this becomes an issue.

It's also worth noting that an inference problem is essentially the same thing as an abstraction.  Perhaps we'll use some kind of type aliasing if it becomes helpful when we explore abstraction-based approaches to inference.

****** Binary Data Inference Problems
******* Classification
One example of an inference problem is classification of binary data.  Suppose we have some data from either pattern0 or pattern1 above as shown earlier and we want to infer the pattern it came from, we can create a problem like so
#+name: binary_data_classification_problems
#+begin_src python :results output :noweb yes :tangle no

  classify_problem0 = InferenceProblem(['v0'],[[1,1,1,1], 'v0'])  
  classify_problem1 = InferenceProblem(['v0'], [[1,1,1,0,0,0], 'v0'])

#+end_src


The solution for classify_problem0 being v0 is [0] and the solution for classify_problem1 being v0 is [1].  The reason the solutions are in a list is that variables may represent several missing elements in a list.  This is better illustrated in the next example.
******* Completion
Another type of problem would be to infer parts of the binary data given we know the pattern e.g.

#+name: binary_data_completion_problems
#+begin_src python :results output :noweb yes :tangle 
  complete_problem0 = InferenceProblem(['v0'], [[1,1,1,'v0'], 1])
  complete_problem1 = InferenceProblem(['v0', 'v1'], [['v0', 1, 'v1'], 0])
#+end_src
The solution for the first problem intuitively is v0 is [0, 0, 0].  The second problem, complete_problem1, raises the issue that problems do not necessarily have a unique answer.  For this problem v1 and v2 could be lists of 1 of arbitrary length e.g. v0 is [1, 1, 1] and v1 is [1] or v0 is [1,1] and v1 is [1,1,1,1].  We'll take a closer look at solutions to inference problems and evaluating them in the next section.

****** Binary Data Solutions
An inference problem is a set of variables along with a list containing those variables.  The solution to inference problems are values that are assigned to those variables (bindings or an environment) and are substituted in the following way.

#+name: substitute_function
#+begin_src python :results value :tangle yes
  def substitute(partial_data, bindings):
      """
      replace variables in the abstraction with the matching values in the bindings
      and return the resulting list
      """
      complete_list = []
      for element in partial_data:
          replacement = swap(element, bindings)
          complete_list += replacement
      return complete_list
  
  def swap(element, bindings):
          if element in bindings.keys():
              return bindings[element]
          elif isinstance(element, list):
              return [substitute(element, bindings)]
          else:
              return [element]
  
#+end_src

We can demonstrate the substitute function on our earlier examples of inference problems like so

#+name: substitution_examples
#+begin_src python :results output :noweb yes :tangle no
  <<substitute_function>>
  <<binary_data_classification_problems>>
  <<binary_data_completion_problems>>
  
  print substitute(classify_problem0.partial_data, {'v0': [0]})
  print substitute(classify_problem1.partial_data, {'v0': [1]})
  print substitute(complete_problem0.partial_data, {'v0': [0,0,0]})
  print substitute(complete_problem1.partial_data, {'v0': [1,1,1], 'v1': [1]})
  print substitute(complete_problem1.partial_data, {'v0': [1,1], 'v1': [1,1,1,1]})
#+end_src

#+RESULTS: substitution_examples
: ['v0']
: [[1, 1, 1, 1], 0]
: [[1, 1, 1, 0, 0, 0], 1]
: [[1, 1, 1, 0, 0, 0], 1]
: [[1, 1, 1, 1, 1], 0]
: [[1, 1, 1, 1, 1, 1, 1], 0]

#+RESULTS: subsitution_examples
Here we used the solutions, i.e. bindings, we thought were intuitively correct for each problem and we get completed lists that look like the prior data we had seen.

We assume for every inference problem there is some "true solution" or set of solutions for it and an algorithm for solving inference problems should try to produce the true solution for a given inference problem.

So for 
#+begin_src python
  classify_problem0 = InferenceProblem(['v0'],[[1,1,1,1], 'v0'])  
#+end_src 
the true solution could be defined as {'v0': [0]}.  
In the case of 
#+begin_src python
  complete_problem1 = InferenceProblem(['v0', 'v1'],[['v0',1,'v1'], 0])  
#+end_src 
the true solution might be the set of all lists containing 1s i.e. {[1], [1,1], [1,1,1],...}

How do we tell if one solution is better than the other?  So given
#+begin_src python
  complete_problem0 = InferenceProblem(['v0'],[[1,1,1,'v0'] '1'])  
  true_solution = {'v0', [0,0,0]}
#+end_src 
If we have an algorithm that has a choice between {'v0', [0,0,1]} and {'v0, [1,1,1]}, how does one compare the two solutions.  It's not clear, but this seems to be something that depends on the algorithm implementation rather than the problem specification.  In terms of the problem either the solution is incorrect or correct and in this case both solutions are incorrect since they don't match the true solution.

***** Algorithm for Inference
This section will describe more formally the simple algorithm for trying to solve inference problems introduced in the section "First Approximation."  Recall the idea is to create a solution, i.e. binding of variables, based on matching the partial data of the inference problem to previously seen data.  Another way to phrase it is we want to find an environment where the the partial data is the same as some prior data we've seen.

The process of matching seems like unification (http://en.wikipedia.org/wiki/Unification_(computer_science)) so it might be worth looking more into the literature if straight-forward approaches run into barriers.  For now though we'll develop our approach by looking at small examples and generalizing.  

Suppose our prior data consists of pattern0 i.e. we have executed the add_pattern0_to_memory code block and now we are faced with classify_problem0.  We want to try and match the partial data of classify_problem0 to the data we've already seen then use that to create a solution.
****** Matching
******* Implementation
Let's look at the pairing of partial data to previous data
#+name: iterate_match
#+begin_src python :results output :noweb yes :tangle no
  <<binary_data_classification_problems>>
  <<add_patter0_to_memory>>
  #TODO define an iterator for Memory to go through the saved data
  
  for memory in memory.memory:
      print classify_problem0.partial_data, memory
  
#+end_src

#+RESULTS: iterate_match
: [[1, 1, 1, 1], 'v0'] [[1], 0]
: [[1, 1, 1, 1], 'v0'] [[1, 1], 0]
: [[1, 1, 1, 1], 'v0'] [[1, 1, 1, 1, 1], 0]
: [[1, 1, 1, 1], 'v0'] [[1, 1], 0]

What should be the output of a matching e.g. if I try to match [[1, 1, 1, 1], 'v0'] with [[1], 0] what should the result be?  What about [[1, 1, 1, 1], 'v0'] and [[1, 1, 1, 1, 1], 0]?  In the future perhaps we'll develop a match function that returns {'v0': 0} as a binding for these two examples by making some sort of "best guess", but for a first pass let's assume there needs to be a perfect match of non-variable parts of the partial data for match to return any bindings (this may be enough when abstraction over prior data is added since matching against abstractions of prior data might have the same effect as making a best guess).  

We still must consider what to do when there are several possible valid matches.  An example being
#+name: example_data_many_matches
#+begin_src python  
  partial_data = [0, 'v0', 0, 'v1']
  prior_data = [0,1,0,1,0,1,0,1]
  
  valid_binding0 = {'v0': [1,0,1], 'v1': [1,0,1]}
  valid_binding1 = {'v0': [1], 'v1': [1,0,1,0,1]}
#+end_src

What is the return type for match? If there is no match then None should be returned.  Perhaps a single binding out of the possibly many bindings.  Maybe all the bindings.  In addition to the binding(s) it might also be useful to return some sort of score with the binding so that we may distinguish between the quality of different bindings.  What are the consequences of the different return types in the broader context of finding a solution to an inference problem?  

This raises another question worth asking about match is whether it should try to match to any part of the prior data or just the top level. E.g.
#name: example_sub_matching
#+begin_src python
  partial_data = [1,0,'v0']
  prior_data = [1,1,[1,0,1]]
  
  sub_match = {'v0', [1]}
#+end_src
Where the sub_match occurs from partial_data being matched to the third element of prior_data.  This is an interesting question because if this is the case then rather than viewing a solution to an inference problem as trying to match to each individual prior piece of data we can view the prior data as one large piece of data and solving the inference problem is a matter of finding a match of the partial_data to this single prior data object.  Either way we'll still probably want a function which matches only the top-level even if it's just a helper function.

In all cases it seems natural that the return of a matching should be a function of matching the individual elements of the partial data.  The possible types to be matched are primitives, variables, and lists.  

#+name: structure_for_match_deprecated
#+begin_src python :noweb yes :tangle no
  def match(partial_data, prior_data):
      if is_variable(partial_data):
          <<match_variable_case>>
      elif is_symbol(partial_data):
          if partial_data == prior_data:
              <<match_symbol_equal_case>>
          else:
              <<match_symbol_not_equal_case>>
      else:
          assert(isinstance(partial_data, list))
          if isinstance(prior_data, list) and len(prior_data) >= len(partial_data):
              #combine the results of matching the individual elements
              <<match_list_case>>
          else:
              <<match_list_no_match>>
#+end_src

The interesting case is when the partial_data is a list.  Let's use the data in example_data_many_matches to guide development of the algorithm.  For now we'll assume matching of the elements occurs via iteration over the list from left to right.  It's not clear why it would be beneficial to do so otherwise, but we'll tag this [DD] (design decision) and can revisit things aren't working.  

It's been asserted that the partial_data is a list, but before we start iterating through and matching elements there are a few checks on the prior_data we can do that would imply there is no match mainly if it is not a list or two small i.e. if there are not enough elements to match with partial_data.
  
Matching elements is kind of tricky because variables in the partial_data can match multiple elements of the corresponding prior_data so we need to keep track of the current position for both lists as we iterate through the partial_data.  

#+name: match_list_case
#+begin_src python :noweb yes 
  matches = []
  prior_data_position = 0
  for partial_data_position, partial_data_element in enumerate(partial_data):
      if is_variable(partial_data_element):
          #this case will need to increment prior_data_position appropriately
          #possibly several steps ahead of partial_data_position
          <<match_list_case_variable_case>>
      else:
          #if it's the last element of partial data and there is more than one element left in
          #prior data then it's not a match
          if partial_data_position == len(partial_data) - 1 and\
            len(prior_data[prior_data_position:]) > 1:
              return None
          else:
              matches.append(match(partial_data_element, prior_data[prior_data_position]))
              prior_data_position += 1
  <<match_list_case_combine_matches>>
  
#+end_src

At this point it's probably a good idea to look at the different possibilites for the return type of matching so we can fill in the missing pieces.
******** single binding no score
There are a couple ways to handle returning a single match.  For now if there is more than one choice we'll select one at random.

We were last looking at the list case of match, i.e.  matching elements of the partial_data to  elements of the  prior_data.  Here is an example of when the current/first element of the partial_data is a variable.
#+name: variable_case_matching_list_example
#+begin_src python :noweb yes
  partial_data = ['v0', 0, 'v1']
  prior_data = [1,0,1,0,1,0,0,1]
  #bindings for v0
  possible_binding0 = {'v0': [1], 'v1': [1,0,1,0,0,1]}
  possible_binding1 = {'v0': [1,0,1], 'v1': [0,1,0,0,1]}
  possible_binding2 = {'v0': [1,0,1,0,1], 'v1': [0,1]}
  possible_binding3 = {'v0': [1,0,1,0,1,0], 'v1':[1]}
#+end_src
The pattern seems to be v0 can match to any prefix of the prior_data ([1], [1,0,1], [1,0,1,0,1], [1,0,1,0,1,0]) that ends before the next character in the partial_data after the variable (0).

In the case where the current variable element is also the last element then it should be bound to the remaining prior_data.

#+name: match_list_case_variable_case
#+begin_src python :noweb yes 
  if partial_data_element == partial_data[-1]:
      matches.append({partial_data_element : prior_data[prior_data_position:]})
  else:
      next_element = partial_data[partial_data_position+1]
      try:
          <<match_list_case_variable_case_has_next_element>>
      except ValueError:
          return None
  
#+end_src

In the case where there is a next element after the current variable element then we can match the variable to any prefix in the prior_data where the element after the last element of the prefix matches the next element in the partial_data, just like in variable_case_matching_list_example for v0.  There is an additional constraint that the remaining prior data after the match must be of greater size than the remaining partial_data and we can ensure this holds by only looking for matches in prior_data up until the position for which the remaining prior_data is the same size as the remaining partial_data.

In the example variable_case_matching_list_example if element is 'v0' then next_element is 0 so we want to find all the positions in prior_data ([1,0,1,0,1,0,0,1]) of 0s e.g. 1, 3, 4, 5, such that there are enough remaining elements in prior_data to match the remaining partial_data. The amount of remaining partial_data is 1 (just the 'v1' element).  If we only look at positions in the prior_data before prior_data[-1:] then any match will have at least 1 element left in prior_data to match the remaining element in the partial_data.

#+name: match_list_case_variable_case_has_next_element_deprecated
#+begin_src python :noweb yes 
  #iterate through the prefixes of prior_data and capture the possible results of matching the variable to it
  variable = partial_data_element
  #remember the possible variable bindings along with the corresponding prior_data_position
  possible_variable_bindings = []
  amount_remaining_needed = len(partial_data[partial_data_position+2:])
  #positions in the prior_data where the prior_data element matches the partial_data element that
  #comes after the variable that is being bound, look at all the positions in prior_data after the current and up to before the tail of prior where the tail is as long as the remaining partial_data
  matching_positions = [i for i in range(prior_data_position+1,len(prior_data[prior_data_position+1:-amount_remaining_needed])+1)
                        if prior_data[i] == next_element]
  
  if len(matching_positions) > 0:
      chosen_match_position = random.choice(matching_positions)
      #bind the prefix of prior_data that ends just before chosen_match_position
      variable_binding = {variable: prior_data[prior_data_position: chosen_match_position]}
      #skip ahead prior_data_position to the point of the match since that will be the next element in the iteration over partial_data
      prior_data_position = chosen_match_position
  
      matches.append(variable_binding)
  else:
      matches.append(None)
#+end_src

We'll need to include the random library when tangling, but what is the best way to do this?
#+name: libs
#+begin_src python :noweb yes :tangle yes
import random
#+end_src

The final part of the match case for lists is combining the matches for the elements in the list.  This means making sure none of the matches were invalid (i.e. had value None) and if everything is ok then merging all the bindings into a single dictionary to be returned.
#+name: match_list_case_combine_matches
#+begin_src python :noweb yes
  if None in matches:
      return None
  else:
      #TODO handle case of same variable appearing in multiple places in the list
      all_bindings = {}
      for bindings in matches:
          all_bindings = dict(all_bindings.items() + bindings.items())
      return all_bindings
#+end_src

The non-list cases for match are fairly straight-forward.
#+name: match_variable_case
#+begin_src python :noweb yes
  return {partial_data: prior_data}
#+end_src


#+name: match_symbol_equal_case
#+begin_src python :noweb yes
  return {}
#+end_src

#+name: match_symbol_not_equal_case
#+begin_src python :noweb yes
  return None
#+end_src

#+name: match_list_no_match
#+begin_src python :noweb yes
  return None 
#+end_src

We need to define a few helper functions in order to run match.  For the type check of whether something is a variable we'll assume for now that variables come in the form 'v' combined with a number e.g. 'v0', 'v142', 'v99'
#+name: is_variable
#+begin_src python :noweb yes :tangle yes
  def is_variable(thing):
      return isinstance(thing, str) and thing[0] == 'v' \
        and thing[1:].isdigit()
    
#+end_src


#+name: is_variable_test
#+begin_src python :results output :noweb yes
  <<is_variable>>
  
  print is_variable('v0')
  print is_variable('0')
  print is_variable('v302')
  
#+end_src

#+RESULTS: is_variable_test
: True
: False
: True

For symbols we'll assume a symbol is anything not a list.
#+name: is_symbol
#+begin_src python :noweb yes :tangle yes
  def is_symbol(thing):
      return not isinstance(thing, list)
#+end_src
******** multiple bindings no score
******** single binding with score
******** multiple bindings with score

  def match(partial_data, prior_data):
      
  Furthmore we can define types of lists as lists with variables in the top level, lists with variables in a deeper level, and lists without variables.  Now if we pair these possibilities 



TODO look at the case where pattern1 has been added to memory.
******** Returning a set of possible bindings
******* Testing
Now that we have an implementation let's try it on some of the examples from earlier starting with the binary data at the beginning of the document.  Recall we'll be trying to apply match to the partial data of an inference problem and the prior data we've stored in memory.  An example of data in memory could be the bit patterns in pattern0

#+begin_src python :noweb yes :results output 
  <<binary_data>>
  for pattern in pattern0:
      print pattern
#+end_src

#+RESULTS:
: [[1], 0]
: [[1, 1], 0]
: [[1, 1, 1, 1, 1], 0]
: [[1, 1], 0]

An example of prior data from an inference problem could be 
#+begin_src python :noweb yes :results output
  <<inference_problem>>
  <<binary_data_classification_problems>>
  print classify_problem0.partial_data
#+end_src

#+RESULTS:
: [[1, 1, 1, 1], 'v0']

Applying match to a case where it should match and shouldn't match would like the following

#+begin_src python :noweb yes :tangle no :results output
  print match([[1, 1, 1, 1], 'v0'], [[1, 1, 1, 1], 0])
  
  print match([[1, 1, 1, 1], 'v0'], [[1, 1, 1, 1, 1], 0])
#+end_src

#+RESULTS
: {'v0': [0]}
: None

We'll also want to look at the cases where matching can have several possibilities such as in variable_case_matching_list_example.

#+begin_src python :noweb yes :tangle no
  for i in range(10):
      print match(['v0', 0, 'v1'], [1,0,1,0,1,0,0,1]) 
#+end_src

#+RESULTS
: {'v0': [1, 0, 1], 'v1': [1, 0, 0, 1]}
: {'v0': [1, 0, 1, 0, 1], 'v1': [0, 1]}
: {'v0': [1, 0, 1, 0, 1], 'v1': [0, 1]}
: {'v0': [1, 0, 1, 0, 1], 'v1': [0, 1]}
: {'v0': [1, 0, 1], 'v1': [1, 0, 0, 1]}
: {'v0': [1, 0, 1, 0, 1, 0], 'v1': [1]}
: {'v0': [1, 0, 1, 0, 1, 0], 'v1': [1]}
: {'v0': [1, 0, 1, 0, 1], 'v1': [0, 1]}
: {'v0': [1], 'v1': [1, 0, 1, 0, 0, 1]}
: {'v0': [1, 0, 1], 'v1': [1, 0, 0, 1]}

Let's take these solutions and substitute them back into the partial data and verify they match the prior data.

#+begin_src python :noweb yes
for i in range(10):
    binding = match(['v0', 0, 'v1'], [1,0,1,0,1,0,0,1])
    print substitute(['v0', 0, 'v1'], binding)
#+end_src

#+RESULTS
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]
: [1, 0, 1, 0, 1, 0, 0, 1]

Now that we have one version of the match function (return single binding, no score), let's move on to complete the loop and return to other versions when the need arises.
****** Problem-solving loop
The original first/naive approach for solving inference problems was to iterate through the prior data and try to find any matches with the partial data.  We'll now formalize this process.  Let's define a class to organize the problem solving functions and data structures.  We'll call it an agent.  It has a memory and a function for taking in inference problems and returning a solution.

#+name: agent
#+begin_src python :noweb yes :tangle yes
  class Agent:
      def __init__(self):
          self.memory = Memory()
  
      def solve(self, inference_problem):
          <<agent_solve>>
#+end_src

In order to solve an inference problem, we'll first extract the partial_data then match it against everything in memory.  To keep things simple we'll return a random binding [DD] or None if no solution was found.

#+name: agent_solve
#+begin_src python :noweb yes
  solutions = [match(inference_problem.partial_data, prior_data)
               for prior_data in self.memory.memory]
  
  solutions = [solution for solution in solutions if solution != None]
  if solutions == []:
      return None
  else:
      return random.choice(solutions)
#+end_src

We can test the function on the original inference problem examples and binary data.

#+begin_src python :noweb yes :tangle no
    <<binary_data>>
    <<binary_data_classification_problems>>
    <<binary_data_completion_problems>>
  
    agent = Agent()
    [agent.memory.add(data) for data in pattern0+pattern1]
    print 'In memory %s' % agent.memory.memory
  
    problems = [classify_problem0, classify_problem1, complete_problem0, complete_problem1]
    for problem in problems:
        print 'problem: %s' % problem.partial_data
        solution = agent.solve(problem)
        print 'solution: %s' % solution
        if solution is not None:
            print 'completion: %s' % substitute(problem.partial_data, solution)
  
#+end_src

#+RESULTS
: In memory [[[1], 0], [[1, 1], 0], [[1, 1, 1, 1, 1], 0], [[1, 1], 0], [[1, 1, 0, 0], 1], [[1, 1, 1, 0, 0, 0], 1], [[1, 1, 1, 1, 0, 0, 0, 0], 1]]
: 
: problem: [[1, 1, 1, 1], 'v0']
: solution: None
: problem: [[1, 1, 1, 0, 0, 0], 'v0']
: solution: {'v0': [1]}
: completion: [[1, 1, 1, 0, 0, 0], 1]
: problem: [[1, 1, 1, 'v0'], 1]
: solution: {'v0': [1, 0, 0, 0, 0]}
: completion: [[1, 1, 1, 1, 0, 0, 0, 0], 1]
: problem: [['v0', 1, 'v1'], 0]
: solution: {'v0': [1, 1, 1], 'v1': [1]}
: completion: [[1, 1, 1, 1, 1], 0]

***** Reflections
We won't go into depth testing this first approach on a wide variety of data since the main point was to work out some of the details for the setup of solving inference problems.  The major limitation of the algorithm was the inability to generalize.  An example was the problem [[1, 1, 1, 1], 'v0'] which intuitively has a solution of {'v0', [1]}.  One possible solution is to use abstraction, which we'll explore in the rest of the document. [add explanation on how abstraction can help]
*** Second Approximation
Our next attempt to solve inference problems will utilize the power of abstraction.  [give some intuitive examples of where abstraction is useful e.g. hierachical planning, etc].  The plan is

1) come up with a few additional inference problems staying with the same two patterns used in binary_data_classfiication_problems and binary_data_completion_problems; these will be used as references while developing the details of the algorithm
2) formally define a process of abstraction based on the lambda abstraction in lambda calculus
3) work out details of how abstraction happens when new data is added to memory as well as how data is stored
4) work out details for matching partial data to possibily abstract data in the memory
5) work out details of how matching is used in the larger problem solving routine


**** More Inference Problems
The previous set of problems had one example problem that could not be solved by matching directly to prior data.  We'll give a few more examples here to both guide development and test the abstraction approach.

#+name: additional_binary_classification_problems
#+begin_src python :noweb yes
  classify_problem2 = InferenceProblem(['v0'], [[1,1,1,1,1,1,1,1,1,1,1,1,1], 'v0'])
  classify_problem3 = InferenceProblem(['v0'], [[1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0], 'v0'])
  
#+end_src

#+name: additional_binary_completion_problems
#+begin_src python :noweb yes
  completion_problem2 = InferenceProblem(['v0'], [[1,'v0'], 1])
#+end_src

We'll also add in more prior_data to make the patterns more salient.
#+name: additional_prior_data
#+begin_src python :noweb yes
  more_pattern0 = [[[2,2], 0], [[3,3,3,3,3], 0], [[5,5,5,5,5,5,5], 0]]
  questionable_pattern0 = [[[1,0,1,0,1,0,1,0], 0], [[1,2,3,1,2,3,1,2,3,1,2,3], 0]]
  
  more_pattern1 = [[[5,5,5,6,6,6],1], [[3,3,2,2],1]]
#+end_src

And pose problems that test this different type of abstraction.
#+name: surface_level_abstraction_problems
#+begin_src python :noweb yes
  classify_problem4 = InferenceProblem(['v0'], [[8,8,8,8,8], 'v0'])
  classify_problem5 = InferenceProblem(['v0'], [[2,2,2,2,2,2,1,1,1,1,1,1], 'v0']
  
  classify_problem6 = InferenceProblem(['v0'], [[4,4,5,5,4,4,5,5,4,4,5,5], 'v0']
  
  completion_problem4 = InferenceProblem(['v0', 'v1'], [[5, 'v0', 6, 'v1'], 1])
  completion_problem5 = InferenceProblem(['v0'], [['v0',9,9,9], 0])
  
  completion_problem6 = InferenceProblem(['v0'], [[1,4,1,1,4,1,1,4,1,'v0',1,4,1], 'v0'])
  completion_problem6 = InferenceProblem(['v0'], [[1,4,1,1,4,1,1,4,1,'v0'], 'v0'])
#+end_src



**** The process of abstraction
The notion of abstraction we'll be using is very similar to the concept of lambda abstraction in the lambda calculus.  Creating abstractions from data will be similar to the process of anti-unification.  The major adaptation will be related to the fact that variables can be replaced with multiple elements that get inserted into their place instead of a single element (see the definition of substitution above).  

Let's first define a data structure for an abstraction.  It is basically the same thing as an inference problem: a set a variables and some data (list, possibly nested) that contain those variables.

#+name: abstraction
#+begin_src python :noweb yes
  Abstraction = InferenceProblem
#+end_src

The basic intuition is abstractions can be made from data by saving what is common between the data and replacing what is different with variables.  The abstraction can then be used to help solve inference problems in a similar way to how the complete prior data in our first approach helped.  If the non-variable parts of the inference problem match to the abstraction and the abstraction has non-variable parts that match up to the variable parts of the partial data then we can bind these (just as in the case where we match complete data to partial data).  The difference (and where the flexibility comes in) is that unlike when matching to complete data not every part of the non-variable partial data has to have an exact counterpart in the abstraction since abstractions also have variables.

So for example suppose our inference problem has the following partial data (with variables can be determined by assumption about their form we used earlier)

[[1, 1, 1, 1], 'v0']

and now suppose in our memory we have the following abstraction

[[1, 'v0"'], 0]

We can match the first part of the first elements then bind to v0" the remaining [1,1,1] of the inference problem's first element.  Now since we first element did not have any conflict in matching we can bind the second element of the inference problem v0 to the abstraction's second element 0.  The important thing is more than one inference problem of the same form can be solved with this abstraction e.g. [[1,1], 'v0'], [[1,1,1,1,1,1,1], 'v0'], etc.  unlike in our first approach where a complete data such as [[1,1,1], 0] could only solve one of these inference problems, specifically [[1,1,1], 'v0'].

Another useful thing about having abstractions in the prior data is that one can perform inference within the prior data which can then be used to help inference in the problem data.  A simple example is as follows.  Suppose the inference problem is

[1,0, 'v0']

and the abstraction in our prior data is

['v0"', 0, 'v0"']

Observe we don't have any concrete element that matches the variable in the partial data in the abstraction, but we can "infer" the first v0" is 1 based on data in the inference problem, then we can use this to say the second v0" is 1 which we can then use create a binding for v0 to 1 and give use a possible solution to the inference problem.

The main things we'll need to work out the details for are how do useful abstractions get created from data and what is the matching process like between an abstraction and inference problem.

***** Creating abstractions
In this section we explore the process of creating abstractions from data.  There are three cases we will look at
1) abstracting from concrete data and concrete data
2) abstracting from concrete data and abstraction
3) abstracting from abstraction and abstraction

The basic idea is to do something like anti-unification where we try to create new data similar to the original data, but with the differences replaced by variables.
****** Abstracting from concrete data and concrete data
Suppose we have the data from pattern0
#+begin_src python :noweb yes
  pattern0 = [[[1], 0], [[1,1], 0], [[1,1,1,1,1], 0], [[1,1], 0]]
#+end_src

If we start with the first piece of data, [[1], 0], in our memory and add the second, [[1,1], 0], what kind of abstractions are reasonable?

One possibility is to note the first element is different and get ['v0', 0]. Another possibility is to compare [1] and [1,1] and create the abstraction [1, 'v0'] and eventually get [[1, 'v0'], 0].  

==Notes on allowing the empty list to be bound to a variable
In the first approximation, the match function assumed variables could not be bound to empty lists, while the second abstraction [[1,'v0'], 0] does assume this.  This will probably make matching more difficult since it increases the number of possible matches.

If a variable can be bound to the empty list then a variable can be placed pretty much anywhere in the data and create a valid abstraction e.g. [['v0', '1, 'v1'], 'v2', 0, 'v3'] can have the binding {'v0': [], 'v1': [1], 'v2': [], 'v3': []} and the substitution would be the second example of pattern0 data [[1,1], 0].
==

Comparing other examples of the pattern0 data would yield similar results e.g. anything compared with [[1], 0] would get the same abstractions and comparing [[1,1], 0] with [[1,1,1,1,1], 0] gives us ['v0', 0] and [[1,1,'v1'], 0] as intuitive abstractions.

Let's do this excercise with pattern1
#+begin_src python :noweb yes
 pattern1 = [[[1,1,0,0],1], [[1,1,1,0,0,0],1], [[1,1,1,1,0,0,0,0],1]]
#+end_src

Comparing [[1,1,0,0],1] with [[1,1,1,0,0,0],1], some reasonable abstractions include
['v0', 1]

[[1,1,'v0'],1]

[[1,1,'v0',0,0,'v1'], 1]

The main difficulty of creating abstractions will be determining the appropriate places to insert variables due to the large number of possibilities.

******* Algorithm Description
The examples from above combined with previous implementations of anti-unification suggest a recursive algorithm for creating abstractions.  If the data are not lists, return the data if they are equal otherwise a variable.  If the data are lists then iterate through the elements and try to create abstractions between them.  This is the tricky part since we need to figure out how to insert variables appropriately into the resulting list.

==Notes on return type
It might make sense to simplify things by not using the class definition for inference problem and abstraction.  If we assume variables have a certain form (which we have been doing already) then inference problems and abstractions are just lists with these special symbols.

For now we'll keep the classes, but we'll have abstract just return the partial_data part (since it's easier to do that with a recursive implementation) then we'll have a function that wraps the partial data in an Abstraction class.

Eventually we will want named abstractions and be able to have lists where the elements are the names of other abstractions along with parameters for those abstractions so having the classes then will be useful, but we can wait for the third approximation or beyond.
==

#+name: abstract
#+begin_src python :noweb yes :tangle yes
  def abstract(data1, data2):
      if not isinstance(data1, list) or not isinstance(data2, list):
          if data1 == data2:
              return data1
          else:
              return variable_generator.generate()
      else:
          #both data are lists so iterate through abstracting the elements together
          <<abstract_list_case>>
#+end_src

For abstracting two lists we need to know when to insert variables and how much of each list the variable should match up to.  In the case of pattern1 abstracting from [[1,1,0,0],1] and [[1,1,1,0,0,0],1] we first check if both lists are the same length, if they are we can pair the elements and abstract them e.g. [1,1,0,0] with [1,1,1,0,0,0] and 1 with 1.

In the case of [1,1,0,0] with [1,1,1,0,0,0] they are not the same length so we have some flexibility as to where variables can go.  The goal is to come up with an abstraction such that both lists are instances of the abstraction.  One possibility is to take the smaller list and try to insert variables such that there is a binding that makes it equal to the larger list.  An element in the smaller list that isn't in the larger can be replaced with a variable.  In general we want to find as many elements that match in the right order then try to insert variables into the resulting list such that there are substitions that create the original lists.  For now we'll develop something ad-hoc and come back to this with a more optimal soluction if it is important [ALGORITHMIC PROBLEM].  One reason it might not be that important to find the optimal abstraction for any pair of data is that good abstractions should be promoted in the outer loop so given many pairs of data the best ones will be found eventually.  It might be worth creating random abstractions to reduce any bias... what are good algorithms for picking out random abstractions?

One algorithm is to take the smaller list and for each element find the first element in the larger list that matches.  Replace any gap with a variable or if there is no match for the current element then replace it with a variable.

For example with SL := [1,1,0,0] and BL := [1,1,1,0,0,0] we iterate through the elements of SL starting with SL[0] that matches to BL[0] then SL[1] matches to BL[1], SL[2] does not match BL[2] so we start binding values in BL to a new variable SL[2] matches to BL[3], SL[3] matches to BL[4] and then SL is out of elements so we create a variable that will bind to the remaining elements of BL (BL[5]).

Let's look at another case where there are non-matching elements in the smaller list e.g. SL=[1,2,2,1] and BL=[1,1,1,1,1] we start by matching SL[0] with BL[0] then find SL[1] does not match BL[1] so we start binding elements of BL to a new variable v0 looking for an element to match to SL[1], but we do not so instead of having a variable between SL[0] and SL[1] we guess SL[1] should be a variable and we'll bind it to BL[1] as kind of an arbitrary design decision [DD].  A similar thing happens with SL[2] which is turned into a variable that binds to BL[2].  SL[3] binds to BL[3] and a variable is created to bind to the remaining BL[4] resulting in [1,v0, v1, 1,v2], but we know we can remove any variables that are next to each other so we get [1,v0,1,v2].  It seems better to we had been able to reach the abstraction [1,v0,1] since there are less variables.


#+name: abstract_list_case
#+begin_src python :noweb yes 
  def fast_forward(position_in_big, big_list, element_in_small):
        for new_position, element_in_big in enumerate(big_list[position_in_big:], start=position_in_big):
            if element_in_big == element_in_small:
                return new_position+1
        return None
  
  element_abstractions = []
  small_list,big_list = sorted([data1,data2], cmp=lambda x,y: len(x)-len(y))
  position_in_big = 0
  for position_in_small, element_in_small in enumerate(small_list):
      element_abstraction = abstract(element_in_small, big_list[position_in_big])
      element_abstractions.append(element_abstraction)
      if is_variable(element_abstraction):
          #fast forward position_in_big until the next element will match element_in_small
          #i.e. try and squeeze non-matching segments in the big list in between matching
          #parts of the small list
          position_in_big = fast_forward(position_in_big, big_list, element_in_small)
          if position_in_big is None:
              position_in_big += 1
          else:
              element_abstractions.append(element_in_small)    
      else:
          position_in_big += 1
  #if there are more elements left in the big list bind them to a variable, observe
  #position_in_big was incremented one last time so we check it against len(big_list) instead
  #of len(big_list)-1 the position of the last element in big_list
  if position_in_big < len(big_list):
      element_abstractions.append(variable_generator.generate())
  return element_abstractions
  
#+end_src

#+name: generate_variable 
#+begin_src python :noweb yes :tangle yes
  class VariableGenerator:
      def __init__(self):
         self._counter = 0
  
      def generate(self):
        new_variable = 'v'+str(self._counter)
        self._counter += 1
        return new_variable
  
  variable_generator = VariableGenerator()
#+end_src

It's worth noting this algorithm has a certain amount of "bias." An example of when this algorithm performs poorly is [1,0,0,0,0] and [0,0,0,0,0,0,0,1], which would result in ['v0', 1, 'v1'] where v0 binds to [] and [0,0,0,0,0,0,0] (in the first and second lists respectively) and v1 binds to [0,0,0,0] and [].  One possible "fix" is to run the above algorithm repeatedly, but each time starting at the next element over e.g. first starting at list[0] then list[1] then list[2] etc using a variable to in front of the starting point to capture and non-matches.  Then take the best match based on the repeated runs.  Are there still poor performing cases (?) Probably... better to let the data bias the abstractions than the algorithms (add more randomness to list abstraction case, let good abstractions become prominent in the outer loop which matches prior data to indference problem partial data).

What are we trying to optimize?  The above examples seem to indicate we'd like to maximize the number of non-variables while minimizing the number of variables in the resulting abstraction (is this true?  in the case of [1,1,0,0] and [1,1,1,0,0,0] we could get fewer variables with [1,1,v0,0,0] but intuitively having two distinct variables with different "types" seems to fit better)


We can test the algorithm on our worked through example to make sure it's what we expect.

#+begin_src python :noweb yes :tangle test.py
  from abstraction import *
  
  <<binary_data>>
  abstraction = abstract(pattern1[0], pattern1[1])
  print abstraction
  assert(abstraction == [[1, 1, 'v0', 0, 0, 'v1'], 1])
  print match(abstraction, pattern1[0])
  print match(abstraction, pattern1[1])
  abstraction2 = abstract(pattern0[0], pattern0[1])
  print abstraction2
#+end_src

******** Changing match
The reason match fails to come up with an appropriate binding is we assumed earlier that the binding for a variable could not be an empty list.  Now that we have formalized the process of abstraction more we find being able to bind a variable to an empty list is useful, so let's adjust the necessary parts of the match function.

It will help to look at an example of how match would work when a variable can be bound to the empty list.  We'll use 

#+name: 
#+begin_src python :noweb yes
  partial_data = [[1, 1, 'v0', 0, 0, 'v1'], 1]
  prior_data = [[1,1,0,0],1]
#+end_src

Stepping through the code the first thing we realize is the constraint that the length of the prior_data needs to be greater than the length of the partial_data is no longer true.  Let's remove that condition

#+name: structure_for_match
#+begin_src python :noweb yes :tangle yes
  def match(partial_data, prior_data):
      if is_variable(partial_data):
          <<match_variable_case>>
      elif is_symbol(partial_data):
          if partial_data == prior_data:
              <<match_symbol_equal_case>>
          else:
              <<match_symbol_not_equal_case>>
      else:
          assert(isinstance(partial_data, list))
          if isinstance(prior_data, list):
              #combine the results of matching the individual elements
              <<match_list_case>>
          else:
              <<match_list_no_match>>
#+end_src



The next place that changes is match_list_case_variable_case_has_next_element.  Previously we used a constraint when matching the element after the variable in the partial_data that the amount of prior_data after the match had to be greater than the amount of partial_data after the match, but this is no longer the case since the prior_data does not have to be longer than the partiaL_data.  

A condition that does need to hold is for the number of non-variables after the chosen match in the prior_data should be at least as many as the non-variables in the partial_data after the variable. One thing to consider thougth is whether checking for this condition guarantees if a binding exists then the match will find it.  If it doesn't then it might be worth keeping the code simpler for now and optimizing (for correctness in this case) after the whole system is built since not having a correct answer each time might not be that important (e.g. there may be handling of fault tolerance elsewhere).

Let's try to find a case where match could fail to produce a valid binding.  The main point where failure could occur is  probably when the variable match is chosen at random.  We need to find a case where one of the possible matches makes it so there is no match as we continue on.  We'll start by trying to use the simplest data possible to try and create this case.  Let the partial_data ['v0', 1, 0] and prior_data be [1,1,1,0].  'v0' can bind to the first two 1s.    What about ['v0', 1, 'v1', 0] then we can get {v0: [1,1]} {v1:[]}.  At this point perhaps if there is a valid binding then it is possible to choose randomly (as long as you leave enough non-variables) and always get a valid binding.  The reason roughly is if there is a valid binding then any remaining non-variables in the partial_data will have a match in the remaining prior_data (why?).

#+name: match_list_case_variable_case_has_next_element
#+begin_src python :noweb yes 
  #iterate through the prefixes of prior_data and capture the possible results of matching the variable to it
  variable = partial_data_element
  #remember the possible variable bindings along with the corresponding prior_data_position
  possible_variable_bindings = []
  
  #positions in the prior_data where the prior_data element matches the partial_data element that
  #comes after the variable that is being bound, look at all the positions in prior_data after the current and up to before the tail of prior where the tail is as long as the remaining partial_data
  matching_positions = find_matching_positions(next_element, prior_data, partial_data,
                                               prior_data_position, partial_data_position)
  
  if len(matching_positions) > 0:
      chosen_match_position = random.choice(matching_positions)
      #bind the prefix of prior_data that ends just before chosen_match_position
      variable_binding = {variable: prior_data[prior_data_position: chosen_match_position]}
      #skip ahead prior_data_position to the point of the match since that will be the next element in the iteration over partial_data
      prior_data_position = chosen_match_position
  
      matches.append(variable_binding)
  else:
      matches.append(None)
#+end_src
In order to find the possible matching positions we need to check two things as we iterate through the prior_data.

1) The next_element in the partial_data matches the current prior_data element.
2) There are at least as many non-variables after the current prior_data element as there are non-variables in the remaining partial_data.

Just like the last version of match we can determine how much of prior_data we need to iterate through to guarantee 2) without having to check for each prior_data element.  We need only determine the number of non-variables in the remaining partial_data then find the tail of the prior_data that contains that number of non-variables and only iterate until the beginning of the tail.
#+name: find_matching_positions
#+begin_src python :noweb yes :tangle yes
  def find_matching_positions(next_element, prior_data, partial_data,
                              prior_data_position, partial_data_position):
      def find_last_prior_position(number_non_variables):
          non_variables_in_prior = 0
          for i in range(len(prior_data)-1, prior_data_position, -1):
              if not is_variable(prior_data[i]):
                  non_variables_in_prior += 1
                  if non_variables_in_prior == number_non_variables:
                      return i
          return prior_data_position
  
      non_variables_in_partial = [element
                                  for element in partial_data[partial_data_position+1:]
                                  if not is_variable(element)]
      #find last position in prior_data where remaining elements have same number of
      #non-variables as non_variables_in_partial-1, the -1 is because we don't count
      #the first non_variable which is the next_element
      assert(non_variables_in_partial[0] == next_element)
      last_prior_position = find_last_prior_position(len(non_variables_in_partial)-1)
      matching_positions = [i for i,element
                            in enumerate(prior_data[prior_data_position:last_prior_position],
                                         start=prior_data_position)
                            if element == next_element]
      return matching_positions
#+end_src

Let's test the update match on the old cases.

#+begin_src python :noweb yes :tangle test.py
  print match([[1, 1, 1, 1], 'v0'], [[1, 1, 1, 1], 0])
  
  print match([[1, 1, 1, 1], 'v0'], [[1, 1, 1, 1, 1], 0])
  for i in range(10):
      print match(['v0', 0, 'v1'], [1,0,1,0,1,0,0,1]) 
#+end_src
